
url= "https://lilianweng.github.io/posts/2023-06-23-agent/"


from langchain_community.document_loaders import WebBaseLoader
web_loader = WebBaseLoader(url)
data = web_loader.load()
data



data[0].metadata
len(data[0].metadata["description"])
data[0].page_content

urls=[
    "https://lilianweng.github.io/posts/2023-06-23-agent/",
    "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/",
]


docs = [WebBaseLoader(url).load() for url in urls]
docs

docs_list=[item for sublist in docs for item in sublist]
docs_list

########################## Text Spliiters   #########################################
from langchain_text_splitters import RecursiveCharacterTextSplitter 
text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100,chunk_overlap=25)
doc_splits = text_splitter.split_documents(docs_list)
doc_splits


########################### Chroma Vector Store #################################
from langchain_community.vectorstores import Chroma

vectorstore=Chroma.from_documents(
    documents=doc_splits,
    collection_name="rag-chrome",
    embedding=embeddings
    
)

